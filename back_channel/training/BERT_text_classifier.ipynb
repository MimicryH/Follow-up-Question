{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bert_seq2seq.tokenizer import Tokenizer, load_chinese_base_vocab\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from bert_seq2seq.utils import load_bert, load_model_params\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "vocab_path = \"G:/bert_seq2seq\\examples/state_dict/roberta_wwm_vocab.txt\"  # roberta模型字典的位置\n",
    "word2idx = load_chinese_base_vocab(vocab_path)\n",
    "\n",
    "dict_bc = {\n",
    "    '1a': '嗯/ok/嗯哼',\n",
    "    '2a': '好的',\n",
    "    '2b': '喔/嗷/昂/奥/这样呀',\n",
    "    '2c': '明白/了解/哦/好吧',\n",
    "    '3a': '真棒/666',\n",
    "    '3b': '挺好/不错',\n",
    "    '4a': '确实/好吧/对/是',\n",
    "    '4b': '可以',\n",
    "    '5a': '啊这',\n",
    "    '5b': '怎会如此？',\n",
    "    '5c': '嗯？/诶？/啊哈？',\n",
    "    '5d': '是么？/真的么？',\n",
    "    '5e': '什么？',\n",
    "    '5f': '厉害',\n",
    "    '5g': '哈哈哈',\n",
    "    '6a': '然后呢？/之后呢？',\n",
    "    '6b': '还有呢？/除此以外呢？',\n",
    "    '6c': '具体说说',\n",
    "    '6d': '比如说？/举个例子？',\n",
    "    '6e': '随便说说',\n",
    "    '6f': '为什么？'\n",
    "}\n",
    "\n",
    "target = list(dict_bc.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "## 自定义dataset\n",
    "class NLUDataset(Dataset):\n",
    "    \"\"\"\n",
    "    针对特定数据集，定义一个相关的取数据的方式\n",
    "    \"\"\"\n",
    "    def __init__(self, sents_src, sents_tgt) :\n",
    "        ## 一般init函数是加载所有数据\n",
    "        super(NLUDataset, self).__init__()\n",
    "        # 读原始数据\n",
    "        # self.sents_src, self.sents_tgt = read_corpus(poem_corpus_dir)\n",
    "        self.sents_src = sents_src\n",
    "        self.sents_tgt = sents_tgt\n",
    "\n",
    "        self.idx2word = {k: v for v, k in word2idx.items()}\n",
    "        self.tokenizer = Tokenizer(word2idx)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        ## 得到单个数据\n",
    "        # print(i)\n",
    "        src = self.sents_src[i]\n",
    "        tgt = self.sents_tgt[i]\n",
    "        token_ids, token_type_ids = self.tokenizer.encode(src)\n",
    "        output = {\n",
    "            \"token_ids\": token_ids,\n",
    "            \"token_type_ids\": token_type_ids,\n",
    "            \"target_id\": tgt\n",
    "        }\n",
    "        return output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sents_src)\n",
    "\n",
    "def padding(indice, max_length, pad_idx=0):\n",
    "    \"\"\"\n",
    "    pad 函数\n",
    "    \"\"\"\n",
    "    pad_indice = [[pad_idx] * max(0, max_length - len(item)) + item for item in indice]\n",
    "    return torch.tensor(pad_indice)\n",
    "\n",
    "def collate_fn(batch, max_len=256):\n",
    "    \"\"\"\n",
    "    动态padding， batch为一部分sample\n",
    "    \"\"\"\n",
    "    token_ids = [data[\"token_ids\"] for data in batch]\n",
    "    max_length = max([len(t) for t in token_ids])\n",
    "    token_type_ids = [data[\"token_type_ids\"] for data in batch]\n",
    "    target_ids = [data[\"target_id\"] for data in batch]\n",
    "    target_ids = torch.tensor(target_ids, dtype=torch.float)\n",
    "\n",
    "    token_ids_padded = padding(token_ids, max_length)\n",
    "    token_type_ids_padded = padding(token_type_ids, max_length)\n",
    "    # target_ids_padded = token_ids_padded[:, 1:].contiguous()\n",
    "    if max_length > max_len:\n",
    "        token_ids_padded = token_ids_padded[:, -max_len:]\n",
    "        token_type_ids_padded = token_type_ids_padded[:, -max_len:]\n",
    "\n",
    "    return token_ids_padded, token_type_ids_padded, target_ids\n",
    "\n",
    "def get_tgt_tensor(_tgt):\n",
    "    index_list = [target.index(t) for t in _tgt]\n",
    "    _zeros = np.zeros(len(target))\n",
    "    _zeros[index_list] = 1\n",
    "    return _zeros\n",
    "\n",
    "def read_corpus(data_path):\n",
    "    \"\"\"\n",
    "    读原始数据\n",
    "    \"\"\"\n",
    "    _src = []\n",
    "    _tgt = []\n",
    "\n",
    "    with open(data_path, encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    for _line in lines:\n",
    "        _l = _line[:-1].split(\"\\t\")\n",
    "        _tgt.append(get_tgt_tensor(_l[1:]))\n",
    "        _src.append(_l[0])\n",
    "    return _src, _tgt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "src, tgt = read_corpus(\"G:/bert_seq2seq\\examples\\data/data_ali_id_out_new.txt\")\n",
    "\n",
    "# check Data\n",
    "for idx in range(5):\n",
    "    print(src[idx], tgt[idx])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, data_path, model_name, model_path, batch_size=8 ,lr=1e-5, tarin_ratio=.8):\n",
    "        # 加载数据\n",
    "        self.sents_src, self.sents_tgt = read_corpus(data_path)\n",
    "        self.tokenizer = Tokenizer(word2idx)\n",
    "        # 判断是否有可用GPU\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(\"device: \" + str(self.device))\n",
    "        # 定义模型\n",
    "        self.bert_model = load_bert(word2idx, model_name=model_name, model_class=\"cls\", target_size=len(target))\n",
    "        ## 加载预训练的模型参数～\n",
    "        load_model_params(self.bert_model, model_path)\n",
    "        # 将模型发送到计算设备(GPU或CPU)\n",
    "        self.bert_model.to(self.device)\n",
    "        # 声明需要优化的参数\n",
    "        self.optim_parameters = list(self.bert_model.parameters())\n",
    "        self.optimizer = torch.optim.Adam(self.optim_parameters, lr=lr, weight_decay=1e-3)\n",
    "        # 声明自定义的数据加载器\n",
    "        dataset = NLUDataset(self.sents_src, self.sents_tgt)\n",
    "        train_num = int(tarin_ratio*len(dataset))\n",
    "        train, validation = torch.utils.data.random_split(dataset,\n",
    "                                                          [train_num, len(dataset) - train_num])\n",
    "        torch.save(train, 'G:/bert_seq2seq\\examples\\data/train_dataset.pt')\n",
    "        torch.save(validation, 'G:/bert_seq2seq\\examples\\data/validation_dataset.pt')\n",
    "        self.dataloader_train =  DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        self.dataloader_validate = DataLoader(validation, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    def train(self, train_epoches, model_save_path):\n",
    "        # 一个epoch的训练\n",
    "        for epoch in range(train_epoches):\n",
    "            # 训练一个epoch\n",
    "            self.bert_model.train()\n",
    "            self.iteration(epoch, model_save_path=model_save_path, train=True)\n",
    "\n",
    "    def save(self, save_path):\n",
    "        \"\"\"\n",
    "        保存模型\n",
    "        \"\"\"\n",
    "        torch.save(self.bert_model.state_dict(), save_path)\n",
    "        print(\"{} saved!\".format(save_path))\n",
    "\n",
    "    def iteration(self, _epoch, model_save_path, train=True):\n",
    "        total_loss = 0\n",
    "        validate_loss = 0\n",
    "        count = 0\n",
    "        count_vali = 0\n",
    "        start_time = time.time() ## 得到当前时间\n",
    "        step = 0\n",
    "        for token_ids, token_type_ids, target_ids in tqdm(self.dataloader_train, position=0, leave=True):\n",
    "            step += 1\n",
    "            if step % 100 == 0:\n",
    "                self.bert_model.eval()\n",
    "            #     test_data = [\"编剧梁馨月讨稿酬六六何念助阵 公司称协商解决\", \"西班牙BBVA第三季度净利降至15.7亿美元\", \"基金巨亏30亿 欲打开云天系跌停自救\"]\n",
    "                for token_ids_validate, token_type_ids_validate, target_ids_validate in self.dataloader_validate:\n",
    "                    token_ids_validate = token_ids_validate.to(self.device)\n",
    "                    # token_type_ids = token_type_ids.to(self.device)\n",
    "                    target_ids_validate = target_ids_validate.to(self.device)\n",
    "                    _, loss_v = self.bert_model(token_ids_validate, labels=target_ids_validate,)\n",
    "                    validate_loss += loss_v.item()\n",
    "                    count_vali += 1\n",
    "                self.bert_model.train()\n",
    "\n",
    "            token_ids = token_ids.to(self.device)\n",
    "            # token_type_ids = token_type_ids.to(self.device)\n",
    "            target_ids = target_ids.to(self.device)\n",
    "            # 因为传入了target标签，因此会计算loss并且返回\n",
    "            _, loss = self.bert_model(token_ids, labels=target_ids,)\n",
    "            # 反向传播\n",
    "            if train:\n",
    "                # 清空之前的梯度\n",
    "                self.optimizer.zero_grad()\n",
    "                # 反向传播, 获取新的梯度\n",
    "                loss.backward()\n",
    "                # 用获取的梯度更新模型参数\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # 为计算当前epoch的平均loss\n",
    "            total_loss += loss.item()\n",
    "            count += 1\n",
    "        end_time = time.time()\n",
    "        spend_time = end_time - start_time\n",
    "        # 打印训练信息\n",
    "        print(\"epoch is \" + str(_epoch)+\". loss is \" + str(total_loss/count)\n",
    "              + \"validation loss is \" + str(validate_loss/count_vali) + \". spend time is \"+ str(spend_time))\n",
    "        # 保存模型\n",
    "        self.save(model_save_path)\n",
    "        return  total_loss/count, validate_loss/count_vali"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "G:/bert_seq2seq\\examples/state_dict/roberta_wwm_pytorch_model.bin loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:43<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 0. loss is 0.31868593383997357validation loss is 0.2997747175395489. spend time is 43.03589940071106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/277 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/bert_seq2seq\\examples/bc_model_2770.bin saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:42<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 1. loss is 0.28079838663447204validation loss is 0.2897897785263402. spend time is 42.505953311920166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/277 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/bert_seq2seq\\examples/bc_model_2770.bin saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:44<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 2. loss is 0.2746343242562635validation loss is 0.2844059513083526. spend time is 44.75880455970764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/277 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/bert_seq2seq\\examples/bc_model_2770.bin saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:44<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 3. loss is 0.2677312177010822validation loss is 0.28142428025603294. spend time is 44.48710322380066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/277 [00:00<00:42,  6.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/bert_seq2seq\\examples/bc_model_2770.bin saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:43<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 4. loss is 0.25944440400342217validation loss is 0.27794495256883756. spend time is 43.920148849487305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/277 [00:00<00:48,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/bert_seq2seq\\examples/bc_model_2770.bin saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:42<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 5. loss is 0.24842019083267514validation loss is 0.276798551423209. spend time is 42.87047004699707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/277 [00:00<00:28,  9.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/bert_seq2seq\\examples/bc_model_2770.bin saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:43<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 6. loss is 0.23392900434534472validation loss is 0.2770306668111256. spend time is 43.57216501235962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/277 [00:00<00:34,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/bert_seq2seq\\examples/bc_model_2770.bin saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:43<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 7. loss is 0.21652083168821645validation loss is 0.2801760519189494. spend time is 43.65998411178589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/277 [00:00<00:49,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/bert_seq2seq\\examples/bc_model_2770.bin saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:43<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 8. loss is 0.20100871172299883validation loss is 0.28975634063993183. spend time is 43.8647882938385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/277 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/bert_seq2seq\\examples/bc_model_2770.bin saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 277/277 [00:43<00:00,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 9. loss is 0.18755484267477524validation loss is 0.2954736953335149. spend time is 43.883718490600586\n",
      "G:/bert_seq2seq\\examples/bc_model_2770.bin saved!\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(data_path=\"G:/bert_seq2seq\\examples\\data/data_ali_id_out_new.txt\", model_name=\"roberta\",\n",
    "                  model_path=\"G:/bert_seq2seq\\examples/state_dict/roberta_wwm_pytorch_model.bin\")\n",
    "train_epoches = 10\n",
    "trainer.train(train_epoches, 'G:/bert_seq2seq\\examples/bc_model_2770.bin')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "G:/bert_seq2seq\\examples/bc_model_2770.bin loaded!\n"
     ]
    },
    {
     "data": {
      "text/plain": "BertClsClassifier(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): BertLayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): BertLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): BertLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): BertLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): BertLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): BertLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): BertLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): BertLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): BertLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): BertLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): BertLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): BertLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): BertLayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): BertLayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (final_dense): Linear(in_features=768, out_features=21, bias=True)\n)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(word2idx)\n",
    "# 判断是否有可用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: \" + str(device))\n",
    "# 定义模型\n",
    "bert_model = load_bert(word2idx, model_name=\"roberta\", model_class=\"cls\", target_size=len(target))\n",
    "\n",
    "## 加载预训练的模型参数～\n",
    "load_model_params(bert_model, \"G:/bert_seq2seq\\examples/bc_model_2770.bin\")\n",
    "# 将模型发送到计算设备(GPU或CPU)\n",
    "bert_model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def test_model(txt, model):\n",
    "    token_ids, token_type_ids = tokenizer.encode(txt)\n",
    "    # token_ids = padding([token_ids], max_length=256, ).to(device)\n",
    "    token_ids = torch.tensor(token_ids, device=device).view(1, -1)\n",
    "    prediction = model(token_ids).tolist()[0]\n",
    "    prediction = pd.Series(index=target, data=prediction).sort_values(ascending=False)\n",
    "    bcs = []\n",
    "    for idx, prob in prediction.iteritems():\n",
    "        bcs.append((idx, dict_bc[idx], prob))\n",
    "    return bcs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "坐地铁，然后有时候开车，主要看公司那边那个停车位方不方便\n",
      " [('3b', '挺好/不错', 0.7948032021522522), ('2b', '喔/嗷/昂/奥/这样呀', 0.7623468041419983), ('5g', '哈哈哈', 0.7367010116577148), ('6a', '然后呢？/之后呢？', 0.720032811164856), ('4a', '确实/好吧/对/是', 0.6540706157684326)]\n",
      "基本上不用了\n",
      " [('4a', '确实/好吧/对/是', 0.666114091873169), ('2b', '喔/嗷/昂/奥/这样呀', 0.6237576007843018), ('6a', '然后呢？/之后呢？', 0.516461968421936), ('3b', '挺好/不错', 0.4081690013408661), ('5g', '哈哈哈', 0.3531256914138794)]\n",
      "然后它有那种就是那个，安上去的贴上去的拿手机控制，然后就比如说我屋里就买了一个，在那卧室，然后就是。比如我我我躺床上要睡觉了，然后我必须关灯再上床，这样已经黑了，我怎么也看不见东西，然后再给遥控，我就直接睡觉时在手机躺床一关就行。\n",
      " [('2b', '喔/嗷/昂/奥/这样呀', 0.493001252412796), ('4a', '确实/好吧/对/是', 0.39568015933036804), ('5b', '怎会如此？', 0.27955082058906555), ('5f', '厉害', 0.2777303457260132), ('3b', '挺好/不错', 0.24921633303165436)]\n",
      "对\n",
      " [('2b', '喔/嗷/昂/奥/这样呀', 0.9273006319999695), ('3b', '挺好/不错', 0.5994013547897339), ('6c', '具体说说', 0.38726145029067993), ('5f', '厉害', 0.33286094665527344), ('6a', '然后呢？/之后呢？', 0.24595743417739868)]\n",
      "对自己能感应比如天亮了，也可以设置它几点几点的自动开，他他自己也会就是根据天气而定，比如天光达到一定亮，他就直接打到。就是那个，就是用用阳光校订器判定\n",
      " [('5g', '哈哈哈', 0.7646089196205139), ('5a', '啊这', 0.5538045763969421), ('4a', '确实/好吧/对/是', 0.5522392988204956), ('6a', '然后呢？/之后呢？', 0.4141620099544525), ('6d', '比如说？/举个例子？', 0.33093971014022827)]\n",
      "小时候见过的\n",
      " [('2b', '喔/嗷/昂/奥/这样呀', 0.9501683115959167), ('4a', '确实/好吧/对/是', 0.3708339333534241), ('3b', '挺好/不错', 0.37019452452659607), ('6a', '然后呢？/之后呢？', 0.3548603653907776), ('5g', '哈哈哈', 0.2042972296476364)]\n",
      "不会\n",
      " [('2b', '喔/嗷/昂/奥/这样呀', 0.8799026012420654), ('6a', '然后呢？/之后呢？', 0.44052770733833313), ('3b', '挺好/不错', 0.3469662666320801), ('6c', '具体说说', 0.20246902108192444), ('2c', '明白/了解/哦/好吧', 0.16529911756515503)]\n",
      "游戏类的，然后汽车类的美食、旅游的差不多这几个大类，看的比较多。\n",
      " [('2b', '喔/嗷/昂/奥/这样呀', 0.9526772499084473), ('6a', '然后呢？/之后呢？', 0.8199705481529236), ('3b', '挺好/不错', 0.41951462626457214), ('5b', '怎会如此？', 0.23569881916046143), ('5f', '厉害', 0.20823340117931366)]\n",
      "然后就安排工作嘛，处理一下，如果有外出的，就把那个行程安排一下，然后就去这个忙那个相关的事情，然后下午因为有些时候比如说你出去的比较远,地点有几个的话就可以那个，如果早一点完了就可以早一点回家，然后如果公司里面还有事情，还要先回公司，然后再回来\n",
      " [('4a', '确实/好吧/对/是', 0.6488163471221924), ('5b', '怎会如此？', 0.5310266613960266), ('5a', '啊这', 0.4179975092411041), ('6a', '然后呢？/之后呢？', 0.41422441601753235), ('3b', '挺好/不错', 0.38953912258148193)]\n",
      "嗯，就是电视和灯光。\n",
      " [('2b', '喔/嗷/昂/奥/这样呀', 0.7520697712898254), ('3b', '挺好/不错', 0.517735481262207), ('5g', '哈哈哈', 0.41667845845222473), ('5b', '怎会如此？', 0.374880313873291), ('6a', '然后呢？/之后呢？', 0.2849615514278412)]\n"
     ]
    }
   ],
   "source": [
    "test_text = [\"坐地铁，然后有时候开车，主要看公司那边那个停车位方不方便\",\n",
    "             \"基本上不用了\",\n",
    "             \"然后它有那种就是那个，安上去的贴上去的拿手机控制，然后就比如说我屋里就买了一个，在那卧室，然后就是。比如我我我躺床上要睡觉了，然后我必须关灯再上床，这样已经黑了，我怎么也看不见东西，然后再给遥控，我就直接睡觉时在手机躺床一关就行。\",\n",
    "             \"对\",\n",
    "             \"对自己能感应比如天亮了，也可以设置它几点几点的自动开，他他自己也会就是根据天气而定，比如天光达到一定亮，他就直接打到。就是那个，就是用用阳光校订器判定\",\n",
    "             \"小时候见过的\",\n",
    "             \"不会\",\n",
    "             \"游戏类的，然后汽车类的美食、旅游的差不多这几个大类，看的比较多。\",\n",
    "             \"然后就安排工作嘛，处理一下，如果有外出的，就把那个行程安排一下，然后就去这个忙那个相关的事情，然后下午因为有些时候比如说你出去的比较远,地点有几个的话就可以那个，如果早一点完了就可以早一点回家，然后如果公司里面还有事情，还要先回公司，然后再回来\",\n",
    "             \"嗯，就是电视和灯光。\"\n",
    "             ]\n",
    "for text in test_text:\n",
    "    print(text + '\\n', test_model(text, bert_model)[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_data = pd.DataFrame(data=tgt, columns=list(dict_bc.values()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "total = label_data.apply(lambda x:x.sum(), axis=0)\n",
    "percentage = total / label_data.shape[0]\n",
    "print(percentage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "liubo_dialog = pd.read_excel(\"D:\\DoobiePJ/2020Ali/ali全部语料\\标注\\新标注/to_do_data_917_liubo.xlsx\")\n",
    "anqi_dialog = pd.read_excel(\"D:\\DoobiePJ/2020Ali/ali全部语料\\标注\\新标注/to_do_data_anqi.xlsx\")\n",
    "hzk_dialog = pd.read_excel(\"D:\\DoobiePJ/2020Ali/ali全部语料\\标注\\新标注/to_do_data_hanzhankang.xlsx\")\n",
    "wpg_dialog = pd.read_excel(\"D:\\DoobiePJ/2020Ali/ali全部语料\\标注\\新标注/to_do_data_wangpengguang.xlsx\")\n",
    "liubo_dialog['conversation'] = '917_liubo'\n",
    "anqi_dialog['conversation'] = 'anqi'\n",
    "hzk_dialog['conversation'] = 'hanzhankang'\n",
    "wpg_dialog['conversation'] = 'wangpengguang'\n",
    "dialog_data = pd.concat([liubo_dialog, anqi_dialog, hzk_dialog, wpg_dialog])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = pd.read_excel(\"G:/bert_seq2seq\\examples\\data/back_channel_test.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bc_idx_dict = {v : k for k, v in dict_bc.items()}\n",
    "txt = []\n",
    "for idx, row in test_data.iterrows():\n",
    "    url = row['url']\n",
    "    start = url.find('to_do_data_') + len('to_do_data_')\n",
    "    end = url.find('？') - len('.jpg')\n",
    "    info = url[start:end].split('-')\n",
    "    print(info)\n",
    "    select_row = dialog_data[(dialog_data['conversation']==info[0])&(dialog_data['Unnamed: 0']==int(info[1]))]\n",
    "    stc = select_row['对话文本'].iloc[0]\n",
    "    # 处理label\n",
    "    labels = json.loads(row['label'])\n",
    "    idx = []\n",
    "    for label in labels:\n",
    "        for l in label['option']:\n",
    "            if l != '以上均不是':\n",
    "                idx.append(bc_idx_dict[l])\n",
    "    if len(idx) < 1:\n",
    "        idx = ['1a', '2a']\n",
    "    line = stc + '\\t' + '\\t'.join(idx) + '\\n'\n",
    "    txt.append(line)\n",
    "    print(line)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"G:/bert_seq2seq\\examples\\data/back_channel_test.txt\", \"w\", encoding=\"utf-8\") as fp:\n",
    "    fp.writelines(txt)\n",
    "    fp.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "src_test, tgt_test = read_corpus(\"G:/bert_seq2seq\\examples\\data/back_channel_test.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "corr = 0\n",
    "pppredictions = []\n",
    "for line in txt:\n",
    "    data = line.split('\\t')\n",
    "    stc = data[0]\n",
    "    if len(stc)>256:\n",
    "        stc = stc[-256:]\n",
    "    tgts = data[1:]\n",
    "    predictions = test_model(stc, bert_model)\n",
    "    pppredictions.append(predictions)\n",
    "    for pred_ in predictions[:5]:\n",
    "        if pred_[0] in tgts:\n",
    "            corr += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(corr/len(stc))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# train_data = torch.load('G:/bert_seq2seq\\examples\\data/train_dataset.pt')\n",
    "validation_data = torch.load('G:/bert_seq2seq\\examples\\data/validation_dataset.pt')\n",
    "\n",
    "the_dataloader = DataLoader(validation_data, batch_size=8, shuffle=True, collate_fn=collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "label_list = list(dict_bc.keys())\n",
    "def get_tgt(tgt_tensor):\n",
    "    result = []\n",
    "    for i, t in enumerate(tgt_tensor):\n",
    "        if t == 1:\n",
    "            result.append(label_list[i])\n",
    "    return result\n",
    "\n",
    "def get_pred(pred_tensor, top_n):\n",
    "    pred_s = pd.Series(data=pred_tensor.tolist(), index=label_list)\n",
    "    pred_s = pred_s.sort_values(ascending=False)\n",
    "    return pred_s.index[:top_n]\n",
    "\n",
    "def check_prediction(pre_tensor, tgt_tensor, top_n=5):\n",
    "    targets = get_tgt(tgt_tensor)\n",
    "    top_pred = get_pred(pre_tensor, top_n)\n",
    "    for _p in top_pred:\n",
    "        if _p in targets:\n",
    "            return True\n",
    "    return False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for token_ids, token_type_ids, target_ids in the_dataloader:\n",
    "    token_ids = token_ids.to('cuda')\n",
    "    # token_type_ids = token_type_ids.to(self.device)\n",
    "    target_ids = target_ids.to('cuda')\n",
    "    # 因为传入了target标签，因此会计算loss并且返回\n",
    "    predictions, loss = bert_model(token_ids, labels=target_ids,)\n",
    "    for _i, p_tensor in enumerate(predictions):\n",
    "        if check_prediction(p_tensor, target_ids[_i], 1):\n",
    "            correct += 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(get_tgt(target_ids[0]))\n",
    "print(get_pred(predictions[0], 5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "455/554"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "388/554"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=5 0.4566787003610108\n",
      "n=3 0.3194945848375451\n",
      "n=1 0.15162454873646208\n"
     ]
    }
   ],
   "source": [
    "print(\"n=5\", str(253/554))\n",
    "print(\"n=3\", str(177/554))\n",
    "print(\"n=1\", str(84/554))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}